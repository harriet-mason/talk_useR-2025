---
title: "Visualising Uncertainty with ggdibbler"
author: "Harriet Mason"
bibliography: references.bib
institute: "Monash University"
format: 
  revealjs: 
    theme: simple
    slide-number: true
editor_options: 
  chunk_output_type: console
title-slide-attributes:
  data-background-image: /images/gglogo1.jpg
  data-background-size: contain
  data-background-opacity: "0.2"
  smaller: true
---


```{r}
#| label: setup
#| include: false
library(tidyverse)
library(ggdibbler)
library(gt)
library(distributional)
library(cowplot)
library(gridExtra)
options(digits=3, 
        repr.plot.width=15,
        repr.plot.height=8)

# ![](images/){fig-align="center"}
```

# What Even is an Uncertainty Visualisation?

## 
![](images/box1.jpg){fig-align="center"}


##
![](images/box2.jpg){fig-align="center"}

##
![](images/box3.jpg){fig-align="center"}

##
![](images/box4.jpg){fig-align="center"}

## 
![](images/box5.jpg){fig-align="center"}

## 
![](images/box6.jpg){fig-align="center"}

## 
![](images/box7.jpg){fig-align="center"}


## 
![](images/box8.jpg){fig-align="center"}


## 
![](images/box9.jpg){fig-align="center"}


## 
![](images/box10.jpg){fig-align="center"}


## 
![](images/box11.jpg){fig-align="center"}

## 
![](images/box12.jpg){fig-align="center"}

## 
![](images/box13.jpg){fig-align="center"}

## 
![](images/box14.jpg){fig-align="center"}

## 
![](images/box15.jpg){fig-align="center"}


## 
![](images/box16.jpg){fig-align="center"}


## 
![](images/box17.jpg){fig-align="center"}

## 
![](images/box18.jpg){fig-align="center"}


## 
![](images/box19.jpg){fig-align="center"}

## 
![](images/box20.jpg){fig-align="center"}

## 
![](images/box21.jpg){fig-align="center"}

## 
![](images/box26.jpg){fig-align="center"}



## 
![](images/box27.jpg){fig-align="center"}


# Can graphics lie?

## Citizen Scientists  
- The Beuro of Meterology has been getting reports about weird temperatures in Iowa
- Apparently, there is a strange spatial pattern in the data
- We get some citizen scientists to measure data at their home and report back

## NOT SO FAST CHUMP
:::: {.columns}

::: {.column width="60%"}

![](images/cops1.jpg)

:::

::: {.column width="40%"}
- Doing science is now illegal in Iowa
- We need to maintain anonymity
- Can only provide the county of each scientist

:::

::::


## The citizen scientist data
```{r}
#| eval: false
#| echo: true
toy_temp
```

```{r}
library(kableExtra)
temp_data <- toy_temp |>
  as_tibble() |>
  select(scientistID, county_name,recorded_temp) |>
  head(5)
kbl(temp_data)
```
`990` citizen scientists participated

## Visualisation goals
- We need to look at the data and identify:
  - The spatial trend (does it exist or not)
  - The statistical strength of the spatial trend

## Approach needs to work for...
![](images/avgjoe.jpg)

## ...and...
![](images/mumtext.jpeg)

# ...and..
![](images/mescam.jpeg)


## Uncertainty visualisation should...
:::: {.columns}

::: {.column width="30%"}
![](images/madsad.jpeg)
:::

::: {.column width="70%"}

<br>

1) Reinforce justified signals
  - We want my mum to trust the results


2) Hide signals that are just noise
  - I don’t want to see something that isn’t there

:::

::::


## Can also think of it as...
![](images/goodtest.jpeg){fig-align="center"}


## We could just plot the data...
```{r}
ggplot(toy_temp) +
  geom_sf(aes(geometry=county_geometry), fill="white") +
  geom_jitter(aes(x=county_longitude, y=county_latitude, colour=recorded_temp), 
              width=7000, height =7000, alpha=0.7) +
  theme_minimal() +
  scale_colour_distiller(palette = "YlOrRd", direction= 1) 
```

## Benefits of plotting the original data
- Plots of the original data can reveal it's limitations
  - Can highlight small sample sizes, high variability, missing values, etc.
- Understanding these limitations can prevent false conclusions
  
## But the original data isnt always...
- Available
  - e.g. anonymised data, theoretical values, etc.
- Relevant
  - Might need to use a sampling distribution rather than original data
- Deterministic
  - e.g. bounded data, estimated values, etc.

## Going back to the example
After we send in our data plot The Beuro of Meterology call us and let us know that we are only looking for a trend in the average values of the counties

- Need to use the sampling distribution
  - We do not have data for the sampling distribution
  - Usually we do not bother, instead we do something like...

## Estimate the county mean

```{r}
#| include: false
# Calculate County Mean
mean_print <- toy_temp |> 
  group_by(county_name) |>
  summarise(temp_mean = mean(recorded_temp)) |>
  as_tibble() |>
  select(county_name, temp_mean) |>
  head(5)

toy_temp_mean <- toy_temp |> 
  group_by(county_name) |>
  summarise(temp_mean = mean(recorded_temp)) 
```

```{r}
#| echo: true
#| eval: false
# Calculate County Mean
toy_temp |> 
  group_by(county_name) |>
  summarise(temp_mean = mean(recorded_temp)) 
```

```{r}
kbl(mean_print)
```

## Visualise with a choropleth map
```{r}
p_choro <- ggplot(toy_temp_mean) +
  geom_sf(aes(geometry=county_geometry, fill=temp_mean)) +
  theme_minimal() +
  scale_fill_distiller(palette = "YlOrRd", direction= 1) +
  xlab("Longitude") +
  ylab("Latitude") +
  labs(fill = "Temperature") 
p_choro
```

## But what if the error is worse?
:::: {.columns}

::: {.column width="60%"}
- Citizens are using some pretty old tools
- The standard error **could** be our estimate or up to three times our estimate.
- The Beuro want's to see both cases

:::

::: {.column width="40%"}
![](images/thermo.jpeg)
:::

::::

## Spot the difference
```{r}
# same plot twice lol
p1 <- p_choro + ggtitle("Low Standard Error")
p2 <- p_choro + ggtitle("High Standard Error")
grid.arrange(p1, p2, nrow = 1)
```


# What does a good uncertainty visualisation look like?

## Solution: add an axis for uncertainty
![](images/bivar.jpeg)

## Does this work? Not really {.smaller}
:::: {.columns}

::: {.column width="30%"}
![](images/bivarface.jpeg)
:::

::: {.column width="70%"}

- Pro
  - Included uncertainty and increased transparency
- Cons
  - High uncertainty signal still very visible so I am still getting scammed
  - 2D palette is harder to read
    - Colour is not a simple 3D space
    - Using saturation hurts accessibility

:::
::::

## Why doesn't this work? 
- Uncertainty is not just another variable…
  - It presents an interesting perceptual problem
- Usually do not want variables to interfere with each other
  - We want to be able to read variables separately
  - In uncertainty visualisation, the opposite is true


## Solution: blend the colours together!
![](images/vsup.jpeg)

## Does this work? Kind of... {.smaller}
:::: {.columns}

::: {.column width="20%"}
![](images/vsupface.jpeg)
:::

::: {.column width="70%"}
- Pros
  - Included uncertainty and increased transparency
  - No false signals
- Cons
  - Still have 2D Colour palette 
  - Standard error at which to blend colours is made up
    - Blend at 1? 2? 4? 37?
    - Impossible to align with hypothesis testing
 
 
:::

::::

## Solution: simulate a sample

![](images/choro.jpeg)

## Does this work? Almost! {.smaller}
:::: {.columns}

::: {.column width="25%"}
![](images/sampleface.jpeg)
:::

::: {.column width="70%"}
- Pros
  - Included uncertainty 
  - High uncertainty interferes with reading of plot (?)
  - 1D colour palette 

- Cons
  - Nightmare to make

:::
::::

# Why are the plots hard?

## Storing uncertain data
- Main issues stem from difficulties to come from storing uncertain data
- Best to represent uncertain data as a distribution
  - That distribution should take up one cell
  - Set up a vectorised distribution object?

## Thank god for `distributional`

```{r}
#| echo: true
toy_temp_est <- toy_temp |> 
  group_by(county_name) |>
  summarise(temp_dist = dist_normal(mu = mean(recorded_temp),
                                    sigma = sd(recorded_temp)/sqrt(n())))
```

```{r}
toy_temp_est |> 
  as_tibble() |>
  select(county_name, temp_dist) |>
  head(5) |>
  kbl()
```

## What does it do?

- `distributional` lets you store distributions in a `tibble` as distribution objects

```{r}
#| echo: true

class(toy_temp_est$temp_dist)
```

## What if we don't use distributional? {.smaller}
- Existing tidy data structures are not great for uncertain data
- e.g. `Vizumap` 
  - Makes Bivariate maps and Pixel (sample) maps
  - Package is designed specifically for uncertainty
- Issues
  - `ggplot2` flexibility is lost
    - e.g. you can only use one of three specific palettes
  - *Very* computationally expensive
    - A simple map can take over a minute to run
  - Need to make every component separately then combine

## Ideal pixelation map code
- the `ggplot` recognises the random variable input, and changes the visualisation accordingly
- Again, touch as few `ggplot` settings as possible

```{r}
#| eval: false
#| echo: true
# Psudo Code
ggplot(data) |>
  geom_sf(aes(geometry = geometry,
              fill = random_variable)) 
```

## `Vizumap` code
```{r}
#| eval: false
#| echo: true

# load the package
library(Vizumap)
library(sf)
sf_use_s2(FALSE)

# Step 1: Format data using bespoke data formatting function
data <- read.uv(data = original_data, 
                estimate = "mean", 
                error = "standard_error")

# Step 2: Pixelate the shapefile
pixelation <- pixelate(geoData = geometry_data, 
                       id = "ID", 
                       # improved - set number of pixels
                       pixelSize = 100)


# Step 3: Build pixel map
pixel_map <- build_pmap(data = data, 
                         distribution = "normal", 
                         pixelGeo = pixelation, 
                         id = "ID", 
                         # You can only use a set palette
                         palette = "Oranges"
                         border = geometry_data)

# Step 4: Print pixel map
view(pixel_map)
```


## Does `distributional` mean we are done?
- Nope
- While the tidy format is useful (and necessary) we now need to extend `ggplot2` to implement it
- Why?

## `ggplot2` was built on the grammar of graphics

![](images/gog1.jpg){fig-align="center"}


## It is designed to take in data

![](images/gog3.jpg){fig-align="center"}

## Not theoretical distributions

![](images/gog4.jpg){fig-align="center"}

## This is what `ggdibbler` is for

![](images/gog5.jpg){fig-align="center"}


# `ggdibbler`

## The `ggdibbler` package
::: {.columns}

::: {.column width="40%"}

![](images/gglogo2.png){fig-align="center"}

:::

::: {.column width="50%"}
- Named after the Australian dibble animal
  - Wanted it to be next to `ggdist`alphabetically in package list
  - dibble = distribution tibble was an accident
- Applies the previously discussed theoretical principles 
:::

::::


## `ggdibbler` Example

```{r}
#| echo: true
#| fig-align: center 

library(ggdibbler)
toy_temp_dist |> 
  ggplot() + 
  geom_sf_sample(aes(geometry = county_geometry,
                     fill=temp_dist))
```

## Wow, look at that software go

```{r}
#| echo: true
#| fig-align: center 
ggplot(toy_temp_dist) +
  geom_sf_sample(aes(geometry=county_geometry, fill=temp_dist),  linewidth=0, n=7) +
  geom_sf(aes(geometry = county_geometry), fill=NA, linewidth=0.5, colour="white") +
  theme_minimal() +
  scale_fill_distiller(palette = "YlOrRd", direction= 1) +
  xlab("Longitude") +
  ylab("Latitude") +
  labs(fill = "Temperature") +
  ggtitle("A super cool and customised plot")

```

## Wow, look at that software go x2

```{r}
#| echo: true
#| fig-align: center 
ggplot(toy_temp_dist) +
  geom_sf_sample(aes(geometry=county_geometry, fill=temp_dist),  linewidth=0, n=7) +
  geom_sf(aes(geometry = county_geometry), fill=NA, linewidth=0.5, colour="white") +
  theme_minimal() +
  scale_fill_distiller(palette = "YlOrRd", direction= 1) +
  xlab("Longitude") +
  ylab("Latitude") +
  labs(fill = "Temperature") +
  ggtitle("A super cool and customised plot")

```

## `ggdibbler` Future Plans {.smaller}
- Implement `ggdibbler` variations of other `geom_*()` functions
  - e.g. `geom_point()`, etc.
  - currently only has one function (I just came back from leave)
- Might implement VSUP into the package
  - `ggplot2` was *not* designed for accessing colour space directly
- Integrate `dibble` object so that `geom_sf()` automatically does `geom_sf_sample()` if you pass a distribution in

## If you care about software
![](images/ggsite.png){fig-align="center"}

## If you care about theory
![](images/papersite.png){fig-align="center"}

# End


  


## Spell check
```{r, include=FALSE, eval=FALSE}
library(spelling)
qmd <- "presentation.qmd"
ignore <- readLines("WORDLIST")
check_spelling <- spell_check_files(
  qmd,
  ignore = ignore,
  lang = "en_GB"
)
if (nrow(check_spelling) > 0) {
  print(check_spelling)
  stop("Check spelling in Qmd files!")
}
```