---
title: "Visualising Uncertainty with ggdibbler"
author: "Harriet Mason"
bibliography: references.bib
institute: "Supervisors: Di Cook, Sarah Goodwin, Susan Vanderplus"
format: 
  revealjs: 
    theme: simple
    slide-number: true
editor_options: 
  chunk_output_type: console
title-slide-attributes:
  data-background-image: /images/gglogo1.jpg
  data-background-size: contain
  data-background-opacity: "0.2"
  smaller: true
---


```{r}
#| label: setup
#| include: false
library(tidyverse)
library(ggdibbler)
library(gt)
library(distributional)
library(cowplot)
library(gridExtra)
options(digits=3, 
        repr.plot.width=15,
        repr.plot.height=8)

# ![](images/){fig-align="center"}
```

# Intro: <br> What Even is an Uncertainty Visualisation?

## 
![](images/box1.jpg){fig-align="center"}


##
![](images/box2.jpg){fig-align="center"}

##
![](images/box3.jpg){fig-align="center"}

##
![](images/box4.jpg){fig-align="center"}

## 
![](images/box5.jpg){fig-align="center"}

## 
![](images/box6.jpg){fig-align="center"}

## 
![](images/box7.jpg){fig-align="center"}


## 
![](images/box8.jpg){fig-align="center"}


## 
![](images/box9.jpg){fig-align="center"}


## 
![](images/box10.jpg){fig-align="center"}


## 
![](images/box11.jpg){fig-align="center"}

## 
![](images/box12.jpg){fig-align="center"}

## 
![](images/box13.jpg){fig-align="center"}

## 
![](images/box14.jpg){fig-align="center"}

## 
![](images/box15.jpg){fig-align="center"}


## 
![](images/box16.jpg){fig-align="center"}


## 
![](images/box17.jpg){fig-align="center"}

## 
![](images/box18.jpg){fig-align="center"}


## 
![](images/box19.jpg){fig-align="center"}

## 
![](images/box20.jpg){fig-align="center"}

## 
![](images/box21.jpg){fig-align="center"}

## 
![](images/box26.jpg){fig-align="center"}



## 
![](images/box27.jpg){fig-align="center"}


# Part 1: <br> Can graphics lie?

## Citizen Scientists  
- Have been getting reports about weird temperatures in Iowa
- Apparently, there is a strange spatial pattern in the data
- We get some citizen scientists to measure data at their home and report back

## NOT IF I HAVE ANYTHING TO DO WITH IT
:::: {.columns}

::: {.column width="60%"}

![](images/cops1.jpg)

:::

::: {.column width="40%"}
- Doing science is now illegal in Iowa
- We need to maintain anonymity
- Can only provide the county of each scientist

:::

::::


## The Citizen scientist data
```{r}
#| eval: false
#| echo: true
toy_temp
```

```{r}
library(kableExtra)
temp_data <- toy_temp |>
  as_tibble() |>
  select(scientistID, county_name,recorded_temp) |>
  head(5)
kbl(temp_data)
```
`990` citizen scientists participated

## Looking at the data
- We need to look at the data and identify:
  - The spatial trend (does it exist or not)
  - The statistical strength of the spatial trend

## We are not only communicating with...
![](images/avgjoe.jpg)

## We are also communicating with...
![](images/mumtext.jpeg)

# ...and myself
![](images/mescam.jpeg)


## Good metrics
![](images/goodtest.jpeg)


## If available, we plot the original data
```{r}
ggplot(toy_temp) +
  geom_sf(aes(geometry=county_geometry), fill="white") +
  geom_jitter(aes(x=county_longitude, y=county_latitude, colour=recorded_temp), 
              width=7000, height =7000, alpha=0.7) +
  theme_minimal() +
  scale_colour_distiller(palette = "YlOrRd", direction= 1) +
  ggtitle("Can you see a spatial trend?")
```

## Benefits of plotting the original data
- Plots of the original data can reveal it's limitations
  - Can highlight small sample sizes, high variability, missing values, etc.
- Understanding these limitations can prevent false conclusions
  
## But the original data isnt always...
- Available
  - e.g. anonymised data, theoretical values, etc.
- Relevant
  - Might need to use a sampling distribution rather than original data
- Deterministic
  - e.g. bounded data, estimated values, etc.

## Going back to the example
After we send in our data plot The Beuro of Meterology call us and let us know that we are only looking for a trend in the average values of the counties
- Need to use the sampling distribution
  - We do not have data for the sampling distribution
  - Usually we do not bother, instead we do something like...

## Estimate the county mean

```{r}
#| include: false
# Calculate County Mean
mean_print <- toy_temp |> 
  group_by(county_name) |>
  summarise(temp_mean = mean(recorded_temp)) |>
  as_tibble() |>
  select(county_name, temp_mean) |>
  head(5)

toy_temp_mean <- toy_temp |> 
  group_by(county_name) |>
  summarise(temp_mean = mean(recorded_temp)) 
```

```{r}
#| echo: true
#| eval: false
# Calculate County Mean
toy_temp |> 
  group_by(county_name) |>
  summarise(temp_mean = mean(recorded_temp)) 
```

```{r}
kbl(mean_print)
```

## Visualise with a choropleth map
```{r}
p_choro <- ggplot(toy_temp_mean) +
  geom_sf(aes(geometry=county_geometry, fill=temp_mean)) +
  theme_minimal() +
  scale_fill_distiller(palette = "YlOrRd", direction= 1) +
  xlab("Longitude") +
  ylab("Latitude") +
  labs(fill = "Temperature") +
  ggtitle("Can you see the spatial trend?")
p_choro
```

## The meteorologists are harassing me
:::: {.columns}

::: {.column width="60%"}
- The Beuro of Meterology calls AGAIN
- Citizens are using some pretty old tools
- The standard error **could** be our estimate or up to three times that.
- The Beuro want's to see both cases

:::

::: {.column width="40%"}
![](images/thermo.jpeg)
:::

::::

## Spot the difference
```{r}
# same plot twice lol
p1 <- p_choro + ggtitle("Low Standard Error")
p2 <- p_choro + ggtitle("High Standard Error")
grid.arrange(p1, p2, nrow = 1)
```
- We cannot send the weather nerds these plots

# The data structure

## Need to integrate the uncertainty information in
- We can represent every estimate as a random variable
- To maintain tidy structure, we would either need to:
  - We would either need to include a complicated function or some kind of vectorised distribution objects
- Spent weeks thinking I was going to have to make this package :(

## Thank god for `distributional`

```{r}
#| echo: true
#| label: false
toy_temp_est <- toy_temp |> 
  group_by(county_name) |>
  summarise(temp_dist = dist_normal(mu = mean(recorded_temp), 
                        sigma = sd(recorded_temp)/sqrt(n())))
```


## Thank god for `distributional`
:::: {.columns}


::: {.column width="40%"}

```{r}
toy_temp_est |> 
  as_tibble() |>
  select(county_name, temp_dist) |>
  head(10) |>
  kbl()
```

:::

::: {.column width="60%"}
```{r}
#| echo: true
class(toy_temp_est$temp_dist)
```

- `distributional` lets you store distributions in a `tibble`
:::

::::


## Uncertainty visualisation should...
:::: {.columns}

::: {.column width="30%"}
![](images/madsad.jpeg)
:::

::: {.column width="70%"}

1) Reinforce justified signals
  - We want my mum to trust the results


2) Hide signals that are just noise
  - I don’t want to see something that isn’t there

*Currently doing neither*

:::

::::

## Solution: add an axis for uncertainty
![](images/bivar.jpeg)

## Does this work? Not really {.smaller}
:::: {.columns}

::: {.column width="30%"}
![](images/bivarface.jpeg)
:::

::: {.column width="70%"}

- Pro
  - Included uncertainty and increased transparency
- Cons
  - High uncertainty signal still very visible so I am still getting scammed
  - 2D palette is harder to read
    - Colour hues are not a simple 2D space
    - Using saturation hurts accessibility

:::
::::

## Why doesn't this work? 
- Uncertainty is not just another variable…
  - We do not have a high-dimension visualisation or basic heuristic problem

- Two dimensions = No interference
  - Normal visualization = GOOD!
  - Uncertainty visualization = BAD! 

## Signal suppression 

![](images/signoise.jpeg){fig-align="center"}

- Visualising uncertainty as noise.
- The error (noise) *should* interfere with our reading of the temperature (signal)
- But *only* when the signal has high error


## Solution: blend the colours together!
![](images/vsup.jpeg)

## Does this work? Kind of... {.smaller}
:::: {.columns}

::: {.column width="20%"}
![](images/vsupface.jpeg)
:::

::: {.column width="70%"}
- Pros
  - Included uncertainty and increased transparency
  - Uncertainty hard to ignore
- Cons
  - Still have 2D Colour palette 
    - Saturation hurts accessibility
  - Standard error at which to blend colours is made up
    - Impossible to align with hypothesis testing
 
 
:::

::::

## Solution: simulate a sample

![](images/choro.jpeg)

## Does this work? Almost! {.smaller}
:::: {.columns}

::: {.column width="25%"}
![](images/sampleface.jpeg)
:::

::: {.column width="70%"}
- Pros
  - Included uncertainty 
  - High uncertainty map has harder to read trend (?)
  - Uncertainty hard to ignore
  - 1D colour palette 
    - No more weird colour space
    - More accessible

- Cons
  - Nightmare to make

:::

  
## What did I live through... {.smaller}
- There are several packages with these issues (I am not saying `Visumap` is bad)
- `Vizumap` is a sample map option
  - Makes Bivariate maps and Pixel (sample) maps
  - Package is designed specifically for uncertainty
- Issues
  - `ggplot2` flexibility is lost
    - e.g. you can only use one of three specific palettes
  - *Very* computationally expensive
    - A simple map can take over a minute to run
  - Need to make every component separately then combine

## Ideal pixelation map code
- the `ggplot` recognises the random variable input, and changes the visualisation accordingly
- Again, touch as few `ggplot` settings as possible

```{r}
#| eval: false
#| echo: true
# Psudo Code
ggplot(data) |>
  geom_sf(aes(geometry = geometries,
              fill = random_variable)) 
```

## `Vizumap` code
```{r}
#| eval: false
#| echo: true

# load the package
library(Vizumap)
library(sf)
sf_use_s2(FALSE)

# Step 1: Format data using bespoke data formatting function
data <- read.uv(data = original_data, 
                estimate = "mean", 
                error = "standard_error")

# Step 2: Pixelate the shapefile
pixelation <- pixelate(geoData = geometry_data, 
                       id = "ID", 
                       # improved - set number of pixels
                       pixelSize = 100)


# Step 3: Build pixel map
pixel_map <- build_pmap(data = data, 
                         distribution = "normal", 
                         pixelGeo = pixelation, 
                         id = "ID", 
                         # You can only use a set palette
                         palette = "Oranges"
                         border = geometry_data)

# Step 4: Print pixel map
view(pixel_map)
```


## Why is integrating uncertainty hard?
- `ggplot2` was built on the grammar of graphics
- Built to take in data, not distributions.

## The grammar of graphics
![](images/gog1.jpg)
## Data as an input

![](images/gog3.jpg){width=50%, fig-align="center"}

![](images/gog4.jpg){width=50%, fig-align="center"}

![](images/gog5.jpg){width=50%, fig-align="center"}

  




## `ggdibbler` Example

```{r}
#| echo: true
#| fig-align: center 

library(ggdibbler)
toy_temp_dist |> 
  ggplot() + 
  geom_sf_sample(aes(geometry = county_geometry,
                     fill=temp_dist))
```

## Wow, look at that software go

```{r}
#| echo: true
#| fig-align: center 
ggplot(toy_temp_dist) +
  geom_sf_sample(aes(geometry=county_geometry, fill=temp_dist),  linewidth=0, n=7) +
  geom_sf(aes(geometry = county_geometry), fill=NA, linewidth=0.5, colour="white") +
  theme_minimal() +
  scale_fill_distiller(palette = "YlOrRd", direction= 1) +
  xlab("Longitude") +
  ylab("Latitude") +
  labs(fill = "Temperature") +
  ggtitle("A super cool and customised plot")

```


## `ggdibbler` Future Plans {.smaller}
- Implement `ggdibbler` variations of other `geom_*()` functions
  - e.g. `geom_point()`, etc.
- Might implement VSUP into the package
  - `ggplot2` was *not* designed for accessing colour space directly
- Integrate `dibble` object so that `geom_sf()` automatically does `geom_sf_sample()` if you pass a distribution in


# End

## Spell check
```{r, include=FALSE, eval=FALSE}
library(spelling)
qmd <- "presentation.qmd"
ignore <- readLines("WORDLIST")
check_spelling <- spell_check_files(
  qmd,
  ignore = ignore,
  lang = "en_GB"
)
if (nrow(check_spelling) > 0) {
  print(check_spelling)
  stop("Check spelling in Qmd files!")
}
```